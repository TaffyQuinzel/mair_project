\begin{abstract}
   In this paper, we set out to validate the Turing Test and explore its role in future AI-research. We present both theoretical and practical objections to the test found in the literature and discuss them in depth. We further discuss different proposed alterations to the test and run an experiment in order to evaluate one such alteration of the test, namely the introduction of spelling errors to the chatbotâ€™s responses.

   Contrary to our hypothesis, we have not found that the introduction of spelling errors allows a chatbot to perform better in a Turing test. However, from a qualitative analysis of the data we have acquired, it seems that the introduction of spelling errors does make the chatbots appear more human-like. We conclude from this that even though the chatbots might not get more intelligent by altering the test in such a way, their performances in the Turing Test can teach us more about human communication.

   We further conclude that there is no definite answer to the question whether or not the test is actually measuring machine intelligence. However, future AI research involving the Turing Test, might help us discover the capabilities that are necessary for the possession of intelligence.
   \textbf{Keywords:}
   Turing; Turing Test; Spell errors; Validity; Relevance; Artificial Intelligence.
\end{abstract}
