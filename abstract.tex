\begin{abstract}
In this paper, we set out to validate the Turing Test and explore its role in future AI-research. We present both theoretical and practical objections to the test found in the literature and discuss them in depth. We further discuss different proposed alterations to the test and run an experiment in order to evaluate one such alteration of the test, namely the introduction of spelling errors to the chatbotâ€™s responses.

     Contrary to our hypothesis, we have not found that the introduction of spelling errors allows a chatbot to perform better in a Turing test. However, from a qualitative analysis of the data we have acquired, it seems that the introduction of spelling errors does make the chatbots appear more human-like. We conclude that while the Turing Test may not be optimal for measuring machine intelligence, it can still be used in other domains, such as in the field of human language interaction.
   \textbf{Keywords:}
   Turing; Turing Test; Spell errors; Validity; Relevance; Artificial Intelligence.
\end{abstract}
