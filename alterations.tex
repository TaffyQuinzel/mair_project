\section{Alterations to the test}
In order to sustain the validity/credibility of the Turing Test, it is advisable to alter the test in some ways. In this section, we will discuss two of those alterations which we will both use in our experiment as well.


\subsection{Probabilistic Support}
In the original Turing Test an interrogator has a conversation with both the human participant and the computer and has to give a yes or no answer to the question that (let’s say) participant 1 was a computer. But given the first objection, it is very hard for a machine to fool one human into believing it is itself a human, let alone fool the majority of people. How could we measure whether the performance of a computer is getting better or not?

Obviously, Turing’s original test can measure the difference in performance between different digital? participants. When the first computer participant can fool 6 out of 20 people it does better than the second one which can only fool 3 out of 20. But A.I. researchers have suggested that it is easy to alter the Turing Test in such a way that it yields more fine-grained statistical data (BRON5). To do this, the altered test should ask participants to provide probabilistic answers, such as: I am 75\% sure that participant 1 is a computer (and therefore I would give a 25\% chance that participant 2 turns out to be a computer). While it might be difficult (or even impossible) to pass the test, we can now at least compare the differences in performances between different digital participants.

This alteration does not only provide scientists with more elaborated statistical data, it also opens up the possibility for an experiment to use a ‘within subject design’. In the original Turing Test it would be only possible to do an experiment to use a ‘between subjects design’, since the participants would only give a yes or no answer.


\subsection{Introducing Spelling Errors}
The Turing Test requires computers to be as human as possible. In order to pass the test, the computer should exhibit human-like behavior and thus should make human-like errors such as not having a perfect memory (not knowing which day of the week it was 8 years ago), not doing complex calculations very fast, and making errors while typing (BRON6). Not only is it the question whether this actually has anything to do with being intelligent, it also makes it hard for the computer which has to take all these subtle human trans logical reasoning errors into account when constructing an answer in order to pass as a human.

Because these trans logical errors have nothing to do with intelligence in general, it may be a good idea to help the computer with that in order to let it have a fair chance of passing the test. In an altered version of the Turing Test, the computer could thus get equipped with some software which automatically prevents the computer of exhibiting non-human behavior such as giving an answer which requires extensive memory (which day of the week was it 8 years ago) or giving an answer to a very difficult mathematical question (which no human can possibly give). Moreover, the software could help the computer by automatically making spelling errors which occur frequently with humans, and by automatically delaying the computer’s answer (according to some distribution). There are of course also more elaborate functions which can be equipped in the software.
