\section{Alterations to the test}
Since our research question is directed at the Turing Test itself and not at completely different tests to measure machine intelligence, we focus on alterations of the original test. Therefore, the suggested alterations take in some sense only the first practical objection into account. Researchers that took the second practical objection serious came up with new tests to measure machine intelligence, which we will only briefly mention.

\subsection{Probabilistic Support}
In the original Turing Test an interrogator has a conversation with both the human participant and the computer and has to give a yes or no answer to the question that (let's say) participant 1 was a computer. But given the first practical objection, it is very hard for a machine to fool one human into believing it is itself a human, let alone fool the majority of people. How could we measure whether the performance of a computer is getting better or not?

Obviously, Turing's original test can measure the difference in performance between different digital participants. When the first computer participant can fool 6 out of 20 people it does better than the second one which can only fool 3 out of 20. But A.I. researchers have suggested that it is easy to alter the Turing Test in such a way that it yields more fine-grained statistical data~\cite{searle1980minds}. To do this, the altered test should ask participants to provide probabilistic answers, such as: I am 75\% sure that participant 1 is a computer (and therefore I would give a 25\% chance that participant 2 turns out to be a computer). While it might be difficult (or even impossible) to pass the test, we can now at least compare the differences in performances between different digital participants.

This alteration does not only provide scientists with more elaborated statistical data, it also opens up the possibility for an experiment to use a \textit{within subject design}. In the original Turing Test it would be only possible to do an experiment to use a \textit{between subjects design}, since the participants would only give a yes or no answer. In this way we cannot only measure the performance of different chatbots in a turing test between different subjects but also for each participant.


\subsection{Introducing human features}
Given the first objection, the Turing Test does not only measure intelligence, but also how human-like the computer is. An intelligent computer can still fail the test since it might not have certain typical human features. To rule out for this possibility, the computer should exhibit human-like behavior and thus should make human-like errors such as not having a perfect memory (not knowing which day of the week it was eight years ago), not doing complex calculations very fast, and making errors while typing~\cite{epstein2009parsing}. Not only is it the question whether this actually has anything to do with being intelligent, it also makes it hard for the computer which has to take all these subtle human trans logical reasoning errors into account when constructing an answer in order to pass as a human.

Because these trans logical errors have nothing to do with intelligence in general, it may be a good idea to help the computer with that in order to let it have a fair chance of passing the test. In an altered version of the Turing Test, the computer could thus get equipped with some software which automatically prevents the computer of exhibiting non-human behavior such as giving an answer which requires extensive memory (which day of the week was it 8 years ago) or giving an answer to a very difficult mathematical question (which no human can possibly give). Moreover, the software could help the computer by automatically making spelling errors which occur frequently with humans, and by automatically delaying the computer's answer (according to some distribution). There are of course also more elaborate functions which can be equipped in the software.


\subsection{Alternative tests}
In this paragraph we will shortly mention two alternative tests that are suggested in the literature. Those alternative tests came up by authors who think the original test is too narrow and should be replaced by a more demanding test. The first one is the Total Turing Test, which is a test that requires responses of all our inputs and not merely our linguistic inputs. Steven Harnad claimed that a more appropriate goal for A.I. research is to create a robot with \textit{sensorimotor capabilities}, which would have the capacity to give the appropriate motoric response to sensory information. Although this sounds like a good alternative test it is not clear that any machine that can pass the Turing Test cannot pass the Total Turing Test. Therefore, right now, there is no final reason to replace Turing's test with the Total Turing Test.

The second alternative test is called the Lovelace Test. This test is proposed by Bringsjord et al. who suggest that achieving to pass this test is a better goal in A.I research. To pass the Lovelace Test, an artificial agent must satisfy the following three conditions:

\begin{enumerate}
   \item The artificial agent A produces output O;
   \item A's output O is not the result of a hardware error, but rather the result of processes that A can repeat;
   \item The designer cannot explain how A produced O by appeal to A's architecture, knowledge base and core functions.
\end{enumerate}

The problem with this new test is that it is hard to decide when the third condition has been achieved. When a computer program is very long and complicated, the designer probably cannot explain in detail how the output was produced. But the designer might be able to give a schematic explanation that refer to the input, the internal processing and the output. Before the Turing Test can be replaced by the Lovelace Test there should be a clear idea of what level of explanation is needed to satisfy the third condition.


